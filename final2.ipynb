{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对keras内置路透社文本数据集进行内容分类（要求模型至少包含有两要素：CNN 、 RNN、 注意力机制）\n",
    "即：Conv + RNN 或RNN + 注意力机制 或 CNN + 注意力机制\n",
    "路透社数据集：<BR>\n",
    "路透社数据集包含许多短新闻及其对应的主题，由路透社在1986年发布。包括46个不同的主题，其中某些主题的样本更多，但是训练集中的每个主题都有至少10个样本。<BR>\n",
    "与IMDB数据集一样，路透社数据集也内置到了Keras库中，并且已经经过了预处理。<BR>\n",
    "#### 提示：\n",
    "由于文本较长，先用CNN卷积上采样到较短长度，再用RNN处理是一个避免梯度消失的方案。<BR>\n",
    "    (由于卷积核为一维，卷积核大小要相应增大到5或7，stride增加到3或5)。<BR>\n",
    "引入注意力机制是另一种克服遗忘的方案。<BR>\n",
    "采用pytorch框架的同学，也利用keras读取数据集内容后进行训练\n",
    "#### 要求：\n",
    "利用callback将最佳模型保存到文件(注意：在\"save\"目录下建立以自己学号命名的子目录，然后在该子目录下保存文件)，\n",
    "最后对最佳模型进行指标评估，展示混淆矩阵\n",
    "#### 数据读取方法：\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.reuters.load_data(num_words=10000, test_split=0.2)\n",
    "\n",
    "#### 考核办法：\n",
    "1）程序功能完成度<BR>\n",
    "2）计算得到的准确率为指标，准确率达到0.7为及格成绩起点，0.8以上优秀<BR>\n",
    "score = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "len(x_train),len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def eda(data,y,maxlen):\n",
    "#     # new_data = data.copy()\n",
    "#     for i in range(len(data)):\n",
    "#         if len(data[i])>30:\n",
    "#             data_ex = list(data[i].copy())\n",
    "#             change_list = random.sample(range(len(data[i])-1),4)\n",
    "#             temp = data_ex[change_list[0]]\n",
    "#             data_ex[change_list[0]] = data_ex[change_list[1]]\n",
    "#             data_ex[change_list[1]] = temp\n",
    "#             del data_ex[change_list[2]]\n",
    "#             del data_ex[change_list[3]]\n",
    "#             # new_data[i] = data_ex\n",
    "#         data = np.append(data,data_ex)\n",
    "#         y = np.append(y,y[i])\n",
    "#     # data = np.vstack((data,new_data))\n",
    "    \n",
    "#     # for i in range(len(data)):\n",
    "#     #     while len(data[i])<maxlen:\n",
    "#     #         data[i] = np.append(data[i],data[i])\n",
    "#     return data,y\n",
    "\n",
    "# # tx,ty = eda(x_train[:2],y_train[:2],350)\n",
    "# # tx,ty\n",
    "# np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx = reuters.get_word_index()\n",
    "idx_to_word = {v:k for k,v in word_idx.items()}\n",
    "\n",
    "\n",
    "from keras_preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "max_len = 350\n",
    "\n",
    "x_train_ex = x_train.copy()\n",
    "x_test_ex = x_test.copy()\n",
    "for i in range(len(x_train)):\n",
    "    while len(x_train_ex[i])<max_len:\n",
    "        x_train_ex[i] = np.append(x_train_ex[i],x_train[i])\n",
    "for i in range(len(x_test)):\n",
    "    while len(x_test_ex[i])<max_len:\n",
    "        x_test_ex[i] = np.append(x_test_ex[i],x_test[i])\n",
    "\n",
    "x_train_pad = sequence.pad_sequences(x_train_ex,maxlen=max_len)\n",
    "x_test_pad = sequence.pad_sequences(x_test_ex,maxlen=max_len)\n",
    "\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Lambda, dot, Activation, concatenate\n",
    "from keras.layers import Layer\n",
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def __call__(self, hidden_states):\n",
    "        hidden_size = int(hidden_states.shape[2])\n",
    "        score_first_part = Dense(hidden_size, use_bias=False, name='attention_score_vec')(hidden_states)\n",
    "\n",
    "        h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(hidden_states)\n",
    "        score = dot([score_first_part, h_t], [2, 1], name='attention_score')\n",
    "        attention_weights = Activation('softmax', name='attention_weight')(score)\n",
    "\n",
    "        context_vector = dot([hidden_states, attention_weights], [1, 1], name='context_vector')\n",
    "        pre_activation = concatenate([context_vector, h_t], name='attention_output')\n",
    "        attention_vector = Dense(128, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n",
    "        return attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Bidirectional\n",
    "from keras.layers import GRU,LSTM,Conv1D,MaxPooling1D\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=8192,output_dim=1024,input_length=max_len))\n",
    "model.add(Conv1D(512,kernel_size=7,strides=5,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=32))\n",
    "# model.add(Dense(64,activation='relu'))\n",
    "model.add(Bidirectional(LSTM(64,dropout=0.5,return_sequences=True)))\n",
    "model.add(Attention())\n",
    "model.add(Dense(46,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Bidirectional,Attention\n",
    "from keras.layers import GRU,LSTM,Conv1D,MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=8000,output_dim=128,input_length=max_len))\n",
    "model.add(Conv1D(64,kernel_size=7,strides=5,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(GRU(32,return_sequences=True,dropout=0.1))\n",
    "model.add(GRU(64,dropout=0.1))\n",
    "model.add(Dense(46,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,Bidirectional,Attention\n",
    "from keras.layers import GRU,LSTM,Conv1D,MaxPooling1D\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1024,output_dim=128,input_length=max_len))\n",
    "model.add(Conv1D(64,kernel_size=7,strides=5,activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(46,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "opt = Adam(learning_rate=1e-3,decay=1e-2)\n",
    "# opt = SGD(learning_rate=0.1,decay=0.07,momentum=0.9,nesterov=True)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "savepath = 'save/3200102349/project2.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=savepath,monitor='val_accuracy',\n",
    "                             verbose=0,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_pad,y_train_onehot,validation_data=(x_test_pad,y_test_onehot),\n",
    "                    shuffle=True,batch_size=32,epochs=40,verbose=1,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(history, train, validation):\n",
    "    plt.plot(history.history[train])\n",
    "    plt.plot(history.history[validation])\n",
    "    plt.title('train history')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','validation'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(history,'accuracy','val_accuracy')\n",
    "show_train_history(history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# bestmodel = load_model(filepath=savepath)\n",
    "# score = bestmodel.evaluate(x_test_pad,y_test_onehot)\n",
    "model.load_weights(savepath)\n",
    "score = model.evaluate(x_test_pad,y_test_onehot)\n",
    "print('score: %.3f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "prediction = np.argmax(bestmodel.predict(x_test_pad),axis=-1)\n",
    "\n",
    "test_labels = y_test\n",
    "pd.crosstab(test_labels,prediction,rownames=['label'],colnames=['predict'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
