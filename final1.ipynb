{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设计一个CNN网络，训练自定义图像数据集的分类操作。 通过优化网络结构与超参数、正则化、数据增强等各种手段，尽可能提高准确率。（要求自建模型，形式不限，不能使用预定义模型）\n",
    "Dataset Context：<BR>\n",
    "This is image data of Natural Scenes around the world.<BR>\n",
    "Dataset Content：<BR>\n",
    "This Data contains around 25k images of size 96x96 distributed under 6 categories.<BR>\n",
    "{'buildings' -> 0, 'forest' -> 1, 'glacier' -> 2,\n",
    "'mountain' -> 3,  'sea' -> 4, 'street' -> 5 }\n",
    "<BR>\n",
    "    \n",
    "#### 要求：\n",
    "1)利用callback将最佳模型保存到文件(注意：在\"save\"目录下建立以自己学号命名的子目录，然后在该子目录下保存文件)。显示loss曲线和accuracy曲线。<BR>\n",
    "2)读取最佳模型进行指标评估并显示结果，展示混淆矩阵。<BR>\n",
    "3)尝试展示典型图片的热力图<BR>\n",
    "\n",
    "#### 考核办法：\n",
    "1）程序功能完成度<BR>\n",
    "2）score = model.evaluate(testset)<BR>\n",
    "计算得到的准确率为指标，达到0.8为及格成绩起点，0.9优秀<BR>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据组织形式：seg_train为训练集，seg_test为测试集，各category子目录下存有jpg文件的图片\n",
    "data/project/\n",
    "    ├── seg_test\n",
    "    │   └── seg_test\n",
    "    │       ├── buildings\n",
    "    │       ├── forest\n",
    "    │       ├── glacier\n",
    "    │       ├── mountain\n",
    "    │       ├── sea\n",
    "    │       └── street\n",
    "    └── seg_train\n",
    "        └── seg_train\n",
    "            ├── buildings\n",
    "            ├── forest\n",
    "            ├── glacier\n",
    "            ├── mountain\n",
    "            ├── sea\n",
    "            └── street\n",
    "\n",
    "#### 数据读取方法：\n",
    "  IMG_SIZE=96\n",
    "  datagen = tf.keras.preprocessing.image.ImageDataGenerator(...)\n",
    "  trainset = datagen.flow_from_directory(trainpath, (IMG_SIZE, IMG_SIZE), batch_size=32)\n",
    "  testset = datagen.flow_from_directory(testpath, (IMG_SIZE, IMG_SIZE), batch_size=32)\n",
    "  \n",
    "model.fit(trainset, validation_data=testset, ...)  #不区分验证集与测试集<BR>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于数据增强，ImageDataGenerator自带很多增强方式，十分方便，请参考相关文档\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "trainpath = 'data/project/seg_train/seg_train'\n",
    "testpath = 'data/project/seg_test/seg_test'\n",
    "IMG_SIZE = 96\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,rotation_range=30,shear_range=0.3,\n",
    "                             height_shift_range=0.2,width_shift_range=0.2)\n",
    "datagen_ori = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainset = datagen.flow_from_directory(trainpath, (IMG_SIZE, IMG_SIZE), batch_size=batch_size)\n",
    "testset = datagen_ori.flow_from_directory(testpath, (IMG_SIZE, IMG_SIZE), \n",
    "                                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),input_shape=(96,96,3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),activation='sigmoid',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "# opt = Adam(learning_rate=1e-3,decay=1e-3)\n",
    "opt = SGD(learning_rate=0.1,decay=1e-3,momentum=0.9,nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "savepath = 'save/3200102349/project1.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=savepath,monitor='val_accuracy',verbose=0,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainset,validation_data=testset,epochs=40,\n",
    "                              steps_per_epoch=len(trainset),\n",
    "                              verbose=1,shuffle=True,\n",
    "                              callbacks=[checkpoint])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(history, train, validation):\n",
    "    plt.plot(history.history[train])\n",
    "    plt.plot(history.history[validation])\n",
    "    plt.title('train history')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','validation'], loc='upper left')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(history,'accuracy','val_accuracy')\n",
    "show_train_history(history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "bestmodel = load_model(filepath=savepath)\n",
    "score = bestmodel.evaluate(testset)\n",
    "print('score: %.3f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prediction = np.argmax(bestmodel.predict(testset),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_labels = testset.classes\n",
    "pd.crosstab(test_labels,prediction,rownames=['label'],colnames=['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_path = 'data/project/seg_train/seg_train/buildings/0.jpg'\n",
    "img_ori = image.load_img(img_path,target_size=(96,96))\n",
    "img_ori = image.img_to_array(img_ori) / 255.\n",
    "plt.imshow(img_ori)\n",
    "plt.show()\n",
    "\n",
    "img = np.expand_dims(img_ori,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weights = bestmodel.layers[-1].get_weights()[0]\n",
    "\n",
    "from keras.models import Model\n",
    "conv_model = Model(inputs=bestmodel.input,\n",
    "                   outputs=(bestmodel.layers[5].output, bestmodel.layers[-1].output))\n",
    "\n",
    "last_conv_out,img_pred = conv_model.predict(img)\n",
    "last_conv_out = np.squeeze(last_conv_out)\n",
    "\n",
    "pred_idx = np.argmax(img_pred[0])\n",
    "print('prediction: %d' % pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_weights_for_pred = last_layer_weights[:,pred_idx]\n",
    "import cv2\n",
    "heat_map = np.dot(last_conv_out,last_layer_weights_for_pred)\n",
    "heat_map = cv2.resize(heat_map,(96,96))\n",
    "plt.imshow(heat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.imshow(img_ori)\n",
    "ax.imshow(heat_map,cmap='jet',alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
